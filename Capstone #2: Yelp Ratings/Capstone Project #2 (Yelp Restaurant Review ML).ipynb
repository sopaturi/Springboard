{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Task\n",
    "\n",
    "The dataset for this section was obtained from the exploratory data analysis section.  The goal of the prediction task is to predict review sentiment, positive or negative, from just the text of the review.  In the previous section, feature engineering was done to create the Bayes average rating feature and the price range feature.  The Bayes average rating feature is a rating that takes into account the number of stars and the number of reviews for a restaurant.  However, these restaurant attributes and others will not be used in classification and will be described in the next section, Feature Selection.  The prediction will determine the probability of the review sentiment being positive as well as whether the prediction for the review is positive or negative.  \n",
    "\n",
    "Below is the first five rows of the dataframe from the previous section.  More wrangling steps need to be done to the data such as conversion of the text reviews into vectors that represent each word in the vector as well as justification for dropping restaurants attributes from the dataset.  Word2Vec will be used to create vector representations for each of the classification methods.  In the deep neural network, the word2vec vector was used as an embedding while in the ensemble methods, the word vectors for each review were averaged by the number of words in a review.  The methods used in this report include a Random Forest model, Gradient Boosted Classifier, Voting Classifier, and a Deep Neural Network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>bayes_avg</th>\n",
       "      <th>price_range</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'RestaurantsReservations': 'False', 'GoodForK...</td>\n",
       "      <td>3BCsAgo_1i4xMuTyLKMLRQ</td>\n",
       "      <td>Food Delivery Services, Juice Bars &amp; Smoothies...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.075876</td>\n",
       "      <td>-115.181726</td>\n",
       "      <td>SkinnyFATS</td>\n",
       "      <td>89118</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We stopped on a whim for a fast lunch before h...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.402220</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'BikeParking': 'True', 'RestaurantsReservatio...</td>\n",
       "      <td>XvOzizKafffkMuk-tIdNcQ</td>\n",
       "      <td>Restaurants, American (Traditional), Breakfast...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.029381</td>\n",
       "      <td>-115.115198</td>\n",
       "      <td>Squeeze In</td>\n",
       "      <td>89123</td>\n",
       "      <td>272.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazing food, great portions and a very creati...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.780229</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'RestaurantsPriceRange2': '2', 'RestaurantsAt...</td>\n",
       "      <td>H_FkQxifSo13B2FWjhp36g</td>\n",
       "      <td>Italian, Restaurants, Pizza</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.122952</td>\n",
       "      <td>-115.168515</td>\n",
       "      <td>Otto Enoteca Pizzeria</td>\n",
       "      <td>89109</td>\n",
       "      <td>684.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yup, same great quality as NYC.  The salads ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.511204</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'BikeParking': 'True', 'RestaurantsTakeOut': ...</td>\n",
       "      <td>S599hCA4kJJO3_b6SRFKoA</td>\n",
       "      <td>Seafood, Restaurants, Mexican, Breakfast &amp; Brunch</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.271357</td>\n",
       "      <td>-115.266850</td>\n",
       "      <td>Michoacan</td>\n",
       "      <td>89149</td>\n",
       "      <td>474.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>as a recent resident of Las Vegas it was imper...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.514450</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'Caters': 'True', 'WheelchairAccessible': 'Tr...</td>\n",
       "      <td>ygaOvp0PLBYaYeN9cZAlGg</td>\n",
       "      <td>Soup, Vietnamese, Barbeque, Restaurants</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.126567</td>\n",
       "      <td>-115.213231</td>\n",
       "      <td>Viet Noodle Bar</td>\n",
       "      <td>89146</td>\n",
       "      <td>984.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Excellent rib eye pho. Nice interior. Good ser...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.906963</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         attributes  \\\n",
       "0           0  {'RestaurantsReservations': 'False', 'GoodForK...   \n",
       "1           1  {'BikeParking': 'True', 'RestaurantsReservatio...   \n",
       "2           2  {'RestaurantsPriceRange2': '2', 'RestaurantsAt...   \n",
       "3           3  {'BikeParking': 'True', 'RestaurantsTakeOut': ...   \n",
       "4           4  {'Caters': 'True', 'WheelchairAccessible': 'Tr...   \n",
       "\n",
       "              business_id                                         categories  \\\n",
       "0  3BCsAgo_1i4xMuTyLKMLRQ  Food Delivery Services, Juice Bars & Smoothies...   \n",
       "1  XvOzizKafffkMuk-tIdNcQ  Restaurants, American (Traditional), Breakfast...   \n",
       "2  H_FkQxifSo13B2FWjhp36g                        Italian, Restaurants, Pizza   \n",
       "3  S599hCA4kJJO3_b6SRFKoA  Seafood, Restaurants, Mexican, Breakfast & Brunch   \n",
       "4  ygaOvp0PLBYaYeN9cZAlGg            Soup, Vietnamese, Barbeque, Restaurants   \n",
       "\n",
       "        city  is_open   latitude   longitude                   name  \\\n",
       "0  Las Vegas      1.0  36.075876 -115.181726             SkinnyFATS   \n",
       "1  Las Vegas      1.0  36.029381 -115.115198             Squeeze In   \n",
       "2  Las Vegas      0.0  36.122952 -115.168515  Otto Enoteca Pizzeria   \n",
       "3  Las Vegas      1.0  36.271357 -115.266850              Michoacan   \n",
       "4  Las Vegas      1.0  36.126567 -115.213231        Viet Noodle Bar   \n",
       "\n",
       "   postal_code  review_count  business_stars  cool  funny  review_stars  \\\n",
       "0        89118        2206.0             4.5     0      0           5.0   \n",
       "1        89123         272.0             4.0     0      0           5.0   \n",
       "2        89109         684.0             3.5     1      1           4.0   \n",
       "3        89149         474.0             3.5     0      0           3.0   \n",
       "4        89146         984.0             4.0     1      0           5.0   \n",
       "\n",
       "                                                text  useful  bayes_avg  \\\n",
       "0  We stopped on a whim for a fast lunch before h...       0   4.402220   \n",
       "1  Amazing food, great portions and a very creati...       0   3.780229   \n",
       "2  Yup, same great quality as NYC.  The salads ar...       1   3.511204   \n",
       "3  as a recent resident of Las Vegas it was imper...       0   3.514450   \n",
       "4  Excellent rib eye pho. Nice interior. Good ser...       0   3.906963   \n",
       "\n",
       "   price_range  sentiment  \n",
       "0            2          1  \n",
       "1            2          1  \n",
       "2            2          1  \n",
       "3            2          0  \n",
       "4            2          1  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lv_reviews_ml=pd.read_csv('lv_reviews_ml')  #read in dataframe with text review and restaurant attributes\n",
    "\n",
    "lv_reviews_ml.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Feature Selection\n",
    "\n",
    "Not all of the relevant features as well as the engineered features were used as inputs to the classifiers for several reasons.  For one, the goal of this project is to predict sentiment from just the text review so that sentiment prediction can be used in any review website, not just Yelp.  If features that describe restaurant attributes are used in this prediction, the models will not necessarily perform as well in another domain with different business attributes. Restaurant attributes other than reviews can change on a daily basis such as review count or number of people that rate the review as cool, funny, or useful.  It is not practical to keep updating the dataframe of reviews and then reclassifying each review along with restaurant attributes as the restaurant attributes keep changing. The following business attributes were dropped: is_open, review_count, business_stars, cool, funny, useful, bayes_avg, and price_range.  \n",
    "\n",
    "A Word2Vec model was used on the text reviews to convert them into vectors.  A vector with a dimension size of 300 was used to represent each word in the Yelp reviews.  According to the shape of the Word2Vec model, not including stop words, 5715 words in the reviews had a corresponding vector representation.   Every word in a review that had a word in the Word2Vec model was converted into a vector and then used as weights in an embedding layer in the deep neural network classifier.  In other other models, the information contained in the sequential order of the words was not accounted because the average of the Wor2Vec vectors for each review was used.  \n",
    "\n",
    "A deep neural network with the same architecture used on the text review was used with multiple features including restaurant attributes.  The metrics for this model such has accuracy, F1-score, and AUC were slightly lower when restaurant attributes were discarded.  If restaurant attributes want to be added to the model in the future, input and outputs need to be created for categorical and numerical variables.  Embedding would be used for categorical and a single dense layer would be used for numerical variables.  Aftwerwards, the overall architecture for all of the variables can be added similar to the one used later on just text reviews.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")  #load word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)  #type of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sooryapaturi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5715, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0.shape #shape of model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics\n",
    "\n",
    "The following metrics were used to compare the performance of the baseline classifier and other classifiers against one another.  \n",
    "\n",
    "**-Classification Accuracy**: Fraction of applications correctly classified\n",
    "\n",
    "\n",
    "$$accuracy = \\frac{tp + tn}{tp+tn+fp+fn}$$\n",
    "\n",
    "\n",
    "where \n",
    "\n",
    "tp is the number of true positives,<br>\n",
    "tn is the number of true negatives,<br>\n",
    "fp is the number of false positives,<br>\n",
    "and fn is the number of false negatives.<br>\n",
    "\n",
    "**-False Positive Rate**: Fraction of denied applications labeled as certified. \n",
    "\n",
    "$$FPR = \\frac{fp}{fp+tn}$$\n",
    "\n",
    "**-False Negative Rate**: Fraction of certified applications classified as denied.  \n",
    "\n",
    "$$FNR = \\frac{fn}{fn+tp}$$\n",
    "\n",
    "\n",
    "**-Balanced Error Rate**: Average of the false negative rate and false positive rate. \n",
    "\n",
    "$$ BER = \\frac{FPR+FNR}{2} $$\n",
    "\n",
    "\n",
    "**-F1 Score**: Another measure of accuracy that uses precision and recall.\n",
    "\n",
    "\n",
    "- Precision is the ratio of true positives to applications that were predicted to be positive.\n",
    "\n",
    "- Recall is the ratio of true positives to applications that were actually positive.  \n",
    "\n",
    "    $$ F{1}\\: Score = \\frac{2*precision*recall}{precision+recall} $$\n",
    "\n",
    "**-AUC**: Area under the curve of the ROC-curve (True positive Rate vs. False Positive Rate).  AUC represents the probability of a randomly drawn positive review having a higher probability of being positive compared to a randomly drawn negative review.  \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark Classifier\n",
    "\n",
    "A benchmark classifier is used to compare all the other classification methods against.\n",
    "\n",
    "-ZeroR (Baseline): The ZeroR classifier used as a baseline simply classifies all reviews as the majority class which in this case is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier  #classifier that labels all samples as majority class\n",
    "\n",
    "\n",
    "X_edit=lv_reviews_ml[\"text\"]  #feature matrix\n",
    "baseline=DummyClassifier(strategy=\"most_frequent\")  #labels all as majority class\n",
    "y_test=lv_reviews_ml[\"sentiment\"] #predicted variable\n",
    "baseline.fit(X_edit,y_test)\n",
    "y_pred_baseline=baseline.predict(X_edit)  #predicted values\n",
    "y_pred_prob_baseline=baseline.predict_proba(X_edit)[:,1]  #predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred_prob_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6635\n",
      "F1-score: 0.79772\n",
      "False Positive Rate: 1.0\n",
      "False Negative Rate: 0.0\n",
      "Balanced Error Rate: 0.5\n",
      "\n",
      "AUC of ROC Curve: 0.5\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0],\n",
       "       [16825, 33175]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred_baseline\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))  #Accuracy\n",
    "print('F1-score: ' +  str(round(f1_score(y_pred, y_test), 5)))  #F1-Score \n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "false_negative_rate = FN/ float(FN + TP)\n",
    "balanced_error_rate = (false_negative_rate+false_positive_rate)/2\n",
    "\n",
    "print('False Positive Rate: ' + str(round(false_positive_rate, 5)))  #FPR\n",
    "print('False Negative Rate: ' + str(round(false_negative_rate, 5)))   #FNR\n",
    "print('Balanced Error Rate: ' + str(round(balanced_error_rate, 5)) + '\\n') #BER\n",
    "\n",
    "print(\"AUC of ROC Curve: \" + \"{}\".format(roc_auc_score(y_test, y_pred_prob_baseline))) #AUC\n",
    "\n",
    "\n",
    "print('Confusion matrix:')\n",
    "confusion_matrix(y_pred, y_test)  #Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Neural Network\n",
    "\n",
    "A deep neural network has multiple layers and finds the correct mathematical operations, whether they be linear or nonlinear to transform the input into the true prediction while minimizing error in the prediciton.  A sequential model is advantageous for text reviews because it takes into account the order of words and positioning of the words when predicting sentiment.  The word vectors in a review do not need to be averaged or concatenated in order to feed into a neural network because a list of words can be interpreted.  Neural networks have many parameters that can be adjusted in order to improve prediction metrics such as the number of layers, number of outputs per layer, types of activation functions, and the number of epochs to run the model for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "review_lines = []\n",
    "lines=lv_reviews_ml['text'].values.tolist()  #create a list of arrays containing review text\n",
    "\n",
    "for line in lines:\n",
    "    line = re.sub(\"[^a-zA-Z]\", \" \", line)  #only keep alphabetical characters \n",
    "    words=line.lower().split()  #lowercase words and split them by space characters\n",
    "    stops=set(stopwords.words(\"english\"))  #define stop words and english stop words\n",
    "    words=[w for w in words if not w in stops]  #filter only words that are not stop words\n",
    "    review_lines.append(words)  #append list of words for each review to review_lines list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index={}\n",
    "f = open('yelp_embedding_word2vec.txt', encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]  #words are in first column of each line\n",
    "    coefs = np.asarray(values[1:])  #coefficients for the wordvec representation are the rest of columns\n",
    "    embeddings_index[word] = coefs  #create mapping of all words to vectors\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sooryapaturi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47518 unique tokens.\n",
      "Shape of review tensor:  (50000, 1022)\n",
      "Shape of sentiment tensor:  (50000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "tokenizer_obj = Tokenizer()  #tokenizer object to convert words into numbers\n",
    "tokenizer_obj.fit_on_texts(review_lines)  #fit the tokenizer on all of the reviews\n",
    "sequences = tokenizer_obj.texts_to_sequences(review_lines)  #convert text to numbers\n",
    "\n",
    "max_length=max([len(s.split()) for s in lines]) #max_len of a review=1022\n",
    "\n",
    "word_index=tokenizer_obj.word_index #all of the words that were tokenized\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "review_pad = pad_sequences(sequences, maxlen=max_length)  #change length of every review to max_length\n",
    "sentiment = lv_reviews_ml['sentiment'].values #convert column to array\n",
    "print('Shape of review tensor: ', review_pad.shape) \n",
    "print('Shape of sentiment tensor: ', sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47519\n"
     ]
    }
   ],
   "source": [
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, 300)) #EMBEDDING_DIM=300\n",
    "\n",
    "for word, i in word_index.items():  #words that were tokenized\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)  #create embedding matrix from word2vec model\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.15596"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=[]\n",
    "for i in sequences:\n",
    "    \n",
    "    total.append(len(i))   #mean number of words per review\n",
    "np.mean(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad_tensor: (30000, 1022)\n",
      "Shape of y_train tensor:  (30000,)\n",
      "Shape of X_val_pad tensor:  (10000, 1022)\n",
      "Shape of y_val tensor:  (10000,)\n",
      "Shape of X_test_pad tensor:  (10000, 1022)\n",
      "Shape of y_test tensor:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten, Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.initializers import Constant\n",
    "\n",
    "model = Sequential()  #initialize sequential model\n",
    "embedding_layer=Embedding(num_words, 300, \n",
    "                          embeddings_initializer=Constant(embedding_matrix),  #wor2vec embedding\n",
    "                         input_length=1022)  #output_dim=300 and input_length=max_length=1022\n",
    "\n",
    "model.add(embedding_layer)  #convert words to vectors\n",
    "\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True)))  #look ahead and backwards as well as long and short term memory\n",
    "model.add(GlobalMaxPool1D())  #find the maximum value for pool inputed\n",
    "model.add(Dense(20, activation=\"relu\"))  #another layer with relu activation function\n",
    "model.add(Dropout(0.05)) #drop 5% of inputs\n",
    "model.add(Dense(1, activation='sigmoid')) #output layer\n",
    "\n",
    "\n",
    "batch_size=100\n",
    "epochs=3\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "VALIDATION_SPLIT=0.2  # split for validation count\n",
    "indices=np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)   #randomize indices\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = sentiment[indices]\n",
    "\n",
    "num_validation_samples = int(VALIDATION_SPLIT*review_pad.shape[0])\n",
    "\n",
    "X_train_pad=review_pad[:-num_validation_samples-10000]   #TRAINING\n",
    "y_train=sentiment[:-num_validation_samples-10000]\n",
    "\n",
    "X_val_pad=review_pad[-num_validation_samples-10000:-10000] #VALIDATION\n",
    "y_val=sentiment[-num_validation_samples-10000:-10000]\n",
    "\n",
    "X_test_pad=review_pad[-num_validation_samples: ] #TEST\n",
    "y_test=sentiment[-num_validation_samples:]\n",
    "\n",
    "print('Shape of X_train_pad_tensor:', X_train_pad.shape)\n",
    "print('Shape of y_train tensor: ', y_train.shape)\n",
    "\n",
    "print('Shape of X_val_pad tensor: ', X_val_pad.shape)\n",
    "print('Shape of y_val tensor: ', y_val.shape)\n",
    "\n",
    "print('Shape of X_test_pad tensor: ', X_test_pad.shape)\n",
    "print('Shape of y_test tensor: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      " - 1228s - loss: 0.3486 - acc: 0.8446 - val_loss: 0.2700 - val_acc: 0.8873\n",
      "Epoch 2/3\n",
      " - 1217s - loss: 0.2062 - acc: 0.9199 - val_loss: 0.2730 - val_acc: 0.8887\n",
      "Epoch 3/3\n",
      " - 1265s - loss: 0.1368 - acc: 0.9507 - val_loss: 0.3064 - val_acc: 0.8784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3e772dd8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train_pad, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val_pad, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test_pad)   #prediction on neural netowrk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8774\n",
      "F1-score: 0.90775\n",
      "False Positive Rate: 0.19778\n",
      "False Negative Rate: 0.08356\n",
      "Balanced Error Rate: 0.14067\n",
      "\n",
      "AUC of ROC Curve: 0.9408858876959147\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2742,  550],\n",
       "       [ 676, 6032]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (prediction > 0.5)\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "print('F1-score: ' +  str(round(f1_score(y_pred, y_test), 5)))\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "false_negative_rate = FN/ float(FN + TP)\n",
    "balanced_error_rate = (false_negative_rate+false_positive_rate)/2\n",
    "\n",
    "print('False Positive Rate: ' + str(round(false_positive_rate, 5)))\n",
    "print('False Negative Rate: ' + str(round(false_negative_rate, 5)))\n",
    "print('Balanced Error Rate: ' + str(round(balanced_error_rate, 5)) + '\\n')\n",
    "\n",
    "print(\"AUC of ROC Curve: \" + \"{}\".format(roc_auc_score(y_test, prediction)))\n",
    "\n",
    "\n",
    "print('Confusion matrix:')\n",
    "confusion_matrix(y_pred, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Methods Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create average feature vecs for train reviews\n",
      "Review 0 of 40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sooryapaturi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 5000 of 40000\n",
      "Review 10000 of 40000\n",
      "Review 15000 of 40000\n",
      "Review 20000 of 40000\n",
      "Review 25000 of 40000\n",
      "Review 30000 of 40000\n",
      "Review 35000 of 40000\n",
      "Create average feature vecs for test reviews\n",
      "Review 0 of 10000\n",
      "Review 5000 of 10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")  #load word2vec model\n",
    "X=lv_reviews_ml[\"text\"]\n",
    "y=lv_reviews_ml[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "#split predictors and predicted variabled with 0.8/0.2 split\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    #Function to average all of the word vectors in a given paragraph\n",
    "    #Initalize a empty numpy array\n",
    "    featureVec=np.zeros((num_features), dtype=\"float32\")\n",
    "    nwords=0\n",
    "    #number of words per review\n",
    "    index2word_set=set(model.wv.index2word)  #list of words in model's vocabulary\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords=nwords+1\n",
    "            featureVec=np.add(featureVec, model[word])  #add vectors per review together\n",
    "     \n",
    "    if nwords != 0:\n",
    "        featureVec=np.divide(featureVec,nwords)  #divded featureVec by number of words in review\n",
    "        return featureVec\n",
    "    else:\n",
    "        return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter=0\n",
    "    reviewFeatureVecs=np.zeros((len(reviews), num_features), dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        if counter % 5000 == 0:\n",
    "            print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "        reviewFeatureVecs[counter]=makeFeatureVec(review, model, num_features) #crate numpy array where each row is average vector for each review\n",
    "        counter=counter+1\n",
    "    return reviewFeatureVecs\n",
    "\n",
    "print('Create average feature vecs for train reviews')\n",
    "\n",
    "\n",
    "clean_train_reviews=[]\n",
    "for line in X_train:\n",
    "    line = re.sub(\"[^a-zA-Z]\", \" \", line) #keep alphabetical characters\n",
    "    words=line.lower().split() #lowercase and split words\n",
    "    stops=set(stopwords.words(\"english\")) #english stop woreds\n",
    "    words=[w for w in words if not w in stops] #keep non stop words\n",
    "    clean_train_reviews.append(words)  #append all words in reviews of train set\n",
    "\n",
    "trainDataVecs=getAvgFeatureVecs(clean_train_reviews, model, num_features=300)\n",
    "\n",
    "\n",
    "print('Create average feature vecs for test reviews')\n",
    "clean_test_reviews= []\n",
    "for line in X_test:\n",
    "    line = re.sub(\"[^a-zA-Z]\", \" \", line)\n",
    "    words=line.lower().split()\n",
    "    stops=set(stopwords.words(\"english\"))\n",
    "    words=[w for w in words if not w in stops]\n",
    "    clean_test_reviews.append(words)\n",
    "    \n",
    "\n",
    "    \n",
    "testDataVecs=getAvgFeatureVecs(clean_test_reviews, model, num_features=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "The random forest classifier is an ensemble method that uses many decision trees that have had bootstrap aggregating or bagging done on the samples. Bagging means that samples are chosen at random with replacement to reduce variance in any single tree. Random forests in addition take a subset of the predictors when constructing a tree so that each tree is more different from one another. The combination of the trees made from bagged samples and subsetted predictors is the random forest result. Compared to a decision tree, a random forest improves accuracy by determining class from the majority of votes for each sample in the many trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a random forest model to the training data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "steps=[('randoforest', RandomForestClassifier(verbose=2))]  #steps of pipeline\n",
    "pipeline=Pipeline(steps) #creation of pipeline\n",
    "\n",
    "parameters_rf = [{   #parameters\n",
    "    'randoforest__n_estimators':      [250],\n",
    "    'randoforest__criterion':         ['gini'],\n",
    "    'randoforest__max_features':      ['auto'],\n",
    "    'randoforest__class_weight':      ['balanced']\n",
    "    #'randoforest__min_samples_leaf':  list(range(2, 8))\n",
    "}]\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf_rf = GridSearchCV(pipeline, parameters_rf, cv=5)  #GridSearch object\n",
    "\n",
    "clf_rf.fit(trainDataVecs, y_train) #fit \n",
    "\n",
    "y_pred_rf=clf_rf.predict(testDataVecs) #predict\n",
    "y_pred_prob_rf = clf_rf.predict_proba(testDataVecs)[:,1] # Compute predicted probabilities: y_pred_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8354\n",
      "F1-score: 0.88356\n",
      "False Positive Rate: 0.37325\n",
      "False Negative Rate: 0.05878\n",
      "Balanced Error Rate: 0.21602\n",
      "\n",
      "AUC of ROC Curve: 0.9111844858919391\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2109,  390],\n",
       "       [1256, 6245]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred_rf\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "print('F1-score: ' +  str(round(f1_score(y_pred, y_test), 5)))\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "false_negative_rate = FN/ float(FN + TP)\n",
    "balanced_error_rate = (false_negative_rate+false_positive_rate)/2\n",
    "\n",
    "print('False Positive Rate: ' + str(round(false_positive_rate, 5)))\n",
    "print('False Negative Rate: ' + str(round(false_negative_rate, 5)))\n",
    "print('Balanced Error Rate: ' + str(round(balanced_error_rate, 5)) + '\\n')\n",
    "\n",
    "print(\"AUC of ROC Curve: \" + \"{}\".format(roc_auc_score(y_test, y_pred_prob_rf)))\n",
    "\n",
    "\n",
    "print('Confusion matrix:')\n",
    "confusion_matrix(y_pred, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Classifier\n",
    "\n",
    "A gradient boosted classifier involves combining a large number of trees.  Each subsequent tree that is constructed is done so based on the least pure splits created by the previous tree.  The trees are added back to the previous tree so that the tree can learn slowly and improve classification accuracy.  An advantage to gradient boosted trees is that compared to a decision tree that may overfit to one set of the data because gradient boosted trees learn by focusing on the worst split in a tree and improve over time.  The disadvantages of gradient boosted trees is that they may overfit compared to random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a random forest model to the training data\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "steps=[('gradientboost', GradientBoostingClassifier(verbose=2))]  #steps of pipeline\n",
    "pipeline=Pipeline(steps) \n",
    "\n",
    "parameters_grad = [{  #parameters\n",
    "    'gradientboost__n_estimators':      [250],\n",
    "    'gradientboost__max_features':      ['auto'],\n",
    "    #'gradientboost__min_samples_leaf':  list(range(2, 7)),\n",
    "    #'gradientboost__loss' :             ['deviance', 'exponential'],\n",
    "    #'gradientboost__learning_rate':     [0.025, 0.05, 0.075, 0.1],\n",
    "}]\n",
    "\n",
    "\n",
    "print(\"Fitting a gradient boosted classifier to labeled training data...\")\n",
    "\n",
    "\n",
    "clf_gb = GridSearchCV(pipeline, parameters_grad, cv=5)  #Gridsearch object\n",
    "\n",
    "clf_gb.fit(trainDataVecs, y_train)  #fit \n",
    "\n",
    "y_pred_gb=clf_gb.predict(testDataVecs)  #predict\n",
    "y_pred_prob_gb = clf_gb.predict_proba(testDataVecs)[:,1] # Compute predicted probabilities: y_pred_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8602\n",
      "F1-score: 0.8971\n",
      "False Positive Rate: 0.25468\n",
      "False Negative Rate: 0.08154\n",
      "Balanced Error Rate: 0.16811\n",
      "\n",
      "AUC of ROC Curve: 0.9260917441054518\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2508,  541],\n",
       "       [ 857, 6094]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred_gb\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "print('F1-score: ' +  str(round(f1_score(y_pred, y_test), 5)))\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "false_negative_rate = FN/ float(FN + TP)\n",
    "balanced_error_rate = (false_negative_rate+false_positive_rate)/2\n",
    "\n",
    "print('False Positive Rate: ' + str(round(false_positive_rate, 5)))\n",
    "print('False Negative Rate: ' + str(round(false_negative_rate, 5)))\n",
    "print('Balanced Error Rate: ' + str(round(balanced_error_rate, 5)) + '\\n')\n",
    "\n",
    "print(\"AUC of ROC Curve: \" + \"{}\".format(roc_auc_score(y_test, y_pred_prob_gb)))\n",
    "\n",
    "\n",
    "print('Confusion matrix:')\n",
    "confusion_matrix(y_pred, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifier\n",
    "\n",
    "A voting classifier involves combining multiple classifiers, in this case a random forest and gradient boosting classifier.  A voting classifier using soft voting averages the probabilities for each sample being positive and assigns the prediction as positive if the average probability across all of the estimators is above 50% in the case of a binary class problem.  An advtange of a voting classifier is that an estimator can be used to mask the errors in prediction of another estimator if the estimators are using different methods of prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              VotingClassifier)\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=250, criterion='gini', max_features='auto', class_weight='balanced', verbose=2)  #estimator 1- rf\n",
    "clf2 = GradientBoostingClassifier(n_estimators=250,  max_features='auto',  verbose=2)  #estimator 2- gb\n",
    "\n",
    "steps = [('voting', VotingClassifier(estimators=[('randoforest', clf1), ('gradientboost', clf2)], voting='soft'))]\n",
    "#steps for pipeline, used soft voting\n",
    "\n",
    "pipeline=Pipeline(steps)\n",
    "params={}\n",
    "\n",
    "clf_vote = GridSearchCV(pipeline, param_grid=params, cv=5) #Gridsearch object\n",
    "\n",
    "clf_vote.fit(trainDataVecs, y_train)  #fit\n",
    "\n",
    "y_pred_vote=clf_vote.predict(testDataVecs) #predict\n",
    "y_pred_prob_vote = clf_vote.predict_proba(testDataVecs)[:,1] # Compute predicted probabilities: y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8563\n",
      "F1-score: 0.8956\n",
      "False Positive Rate: 0.28707\n",
      "False Negative Rate: 0.07099\n",
      "Balanced Error Rate: 0.17903\n",
      "\n",
      "AUC of ROC Curve: 0.9236227802716694\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2399,  471],\n",
       "       [ 966, 6164]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred_vote\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "print('F1-score: ' +  str(round(f1_score(y_pred, y_test), 5)))\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "false_negative_rate = FN/ float(FN + TP)\n",
    "balanced_error_rate = (false_negative_rate+false_positive_rate)/2\n",
    "\n",
    "print('False Positive Rate: ' + str(round(false_positive_rate, 5)))\n",
    "print('False Negative Rate: ' + str(round(false_negative_rate, 5)))\n",
    "print('Balanced Error Rate: ' + str(round(balanced_error_rate, 5)) + '\\n')\n",
    "\n",
    "print(\"AUC of ROC Curve: \" + \"{}\".format(roc_auc_score(y_test, y_pred_prob_vote)))\n",
    "\n",
    "\n",
    "print('Confusion matrix:')\n",
    "confusion_matrix(y_pred, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mClassification Metrics for ML Models \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>BER</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZeroR Baseline</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7977</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy  FPR  FNR  BER  F1 Score  AUC\n",
       "0  ZeroR Baseline    0.6635  1.0  0.0  0.5    0.7977  0.5"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>BER</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8354</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.8836</td>\n",
       "      <td>0.9118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosted Tree</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>0.9261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deep Neural Network</td>\n",
       "      <td>0.8774</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.9409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Accuracy     FPR     FNR     BER  F1-Score     AUC\n",
       "0          Random Forest    0.8354  0.3733  0.0588  0.2160    0.8836  0.9118\n",
       "1  Gradient Boosted Tree    0.8602  0.2547  0.0815  0.1681    0.8971  0.9261\n",
       "2      Voting Classifier    0.8563  0.2871  0.0710  0.1790    0.8956  0.9236\n",
       "3    Deep Neural Network    0.8774  0.1978  0.0836  0.1407    0.9078  0.9409"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print('\\033[1m' + 'Classification Metrics for ML Models \\n')\n",
    "\n",
    "d1 = {'Model': ['ZeroR Baseline'], 'Accuracy': [0.6635], 'FPR': [1.0000], 'FNR': [0.0000], 'BER': [0.50000], 'F1 Score': [0.7977], 'AUC': [0.50000]}\n",
    "\n",
    "d2 = {'Model': ['Random Forest', 'Gradient Boosted Tree', 'Voting Classifier', 'Deep Neural Network'], \n",
    "                 'Accuracy': [0.8354, 0.8602, 0.8563, 0.8774], \n",
    "                 'FPR': [0.3733, 0.2547, 0.2871, 0.1978], \n",
    "                 'FNR': [0.0588, 0.0815, 0.0710, 0.0836],\n",
    "                 'BER': [0.2160, 0.1681, 0.1790, 0.1407],                         \n",
    "                 'F1-Score': [0.8836, 0.8971, 0.8956, 0.9078],\n",
    "                 'AUC': [0.9118, 0.9261, 0.9236, 0.9409]\n",
    "    }\n",
    "df1=pd.DataFrame(data=d1)\n",
    "df2=pd.DataFrame(data=d2)\n",
    "\n",
    "\n",
    "df1\n",
    "df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
